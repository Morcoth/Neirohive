{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "### Шаг 1. Определение функций, которые понадобяться для обучения\n",
    "# преобразование массива в бинарный вид результатов\n",
    "def to_one_hot(Y):\n",
    "    n_col = np.amax(Y) + 1\n",
    "    binarized = np.zeros((len(Y), n_col))\n",
    "    for i in range(len(Y)):\n",
    "        binarized[i, Y[i]] = 1.\n",
    "    return binarized\n",
    "\n",
    "# преобразование массива в необходимый вид\n",
    "def from_one_hot(Y):\n",
    "    arr = np.zeros((len(Y), 1))\n",
    "\n",
    "    for i in range(len(Y)):\n",
    "        l = layer2[i]\n",
    "        for j in range(len(l)):\n",
    "            if(l[j] == 1):\n",
    "                arr[i] = j+1\n",
    "    return arr\n",
    "\n",
    "# сигмоида и ее производная\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_deriv(x):\n",
    "    return sigmoid(x)*(1 - sigmoid(x))\n",
    "\n",
    "# нормализация массива\n",
    "def normalize(X, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
    "    l2[l2 == 0] = 1\n",
    "    return X / np.expand_dims(l2, axis)\n",
    "\n",
    "\n",
    "### Шаг 2. Подготовка тренировочных данных\n",
    "# получения данных из csv файла. укажите здесь путь к файлу Iris.csv\n",
    "iris_data = pd.read_csv(\"Iris.csv\")\n",
    "# print(iris_data.head()) # расскоментируйте, чтобы посмотреть структуру данных\n",
    "\n",
    "# репрезентация данных в виде графиков\n",
    "g = sns.pairplot(iris_data.drop(\"Id\", axis=1), hue=\"Species\")\n",
    "# plt.show() \n",
    "\n",
    "# замена текстовых значений на цифровые\n",
    "iris_data['Species'].replace(['Iris-setosa', 'Iris-virginica', 'Iris-versicolor'], [0, 1, 2], inplace=True)\n",
    "\n",
    "# формирование входных данных\n",
    "columns = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "x = pd.DataFrame(iris_data, columns=columns)\n",
    "x = normalize(x.as_matrix())\n",
    "\n",
    "# формирование выходных данных(результатов)\n",
    "columns = ['Species']\n",
    "y = pd.DataFrame(iris_data, columns=columns)\n",
    "y = y.as_matrix()\n",
    "y = y.flatten()\n",
    "y = to_one_hot(y)\n",
    "\n",
    "# Разделение данных на тренировочные и тестовые\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n",
    "   \n",
    "### Шаг 3. Обученние нейронной сети\n",
    "# присваевание случайных весов\n",
    "w0 = 5*np.random.random((4, 5)) - 1 # для входного слоя   - 4 входа, 3 выхода\n",
    "w1 = 5*np.random.random((5, 3)) - 1 # для внутреннего слоя - 5 входов, 3 выхода\n",
    "\n",
    "# скорость обучения (learning rate)\n",
    "n = 0.1\n",
    "\n",
    "# массив для ошибок, чтобы потом построить график\n",
    "errors = []\n",
    "\n",
    "# процесс обучения\n",
    "for i in range(100000):\n",
    "\n",
    "    # прямое распространение(feed forward)\n",
    "    layer0 = X_train\n",
    "    layer1 = sigmoid(np.dot(layer0, w0))\n",
    "    layer2 = sigmoid(np.dot(layer1, w1))\n",
    "\n",
    "    # обратное распространение(back propagation) с использованием градиентного спуска\n",
    "    layer2_error = y_train - layer2\n",
    "    layer2_delta = layer2_error * sigmoid_deriv(layer2)\n",
    "    \n",
    "    layer1_error = layer2_delta.dot(w1.T)\n",
    "    layer1_delta = layer1_error * sigmoid_deriv(layer1)\n",
    "    \n",
    "    w1 += layer1.T.dot(layer2_delta) * n\n",
    "    w0 += layer0.T.dot(layer1_delta) * n\n",
    "    \n",
    "    error = np.mean(np.abs(layer2_error))\n",
    "    errors.append(error)\n",
    "    accuracy = (1 - error) * 100\n",
    "\n",
    "\n",
    "### Шаг 4. Демонстрация полученных результатов\n",
    "# черчение диаграммы точности в зависимости от обучения\n",
    "plt.plot(errors)\n",
    "plt.xlabel('Обучение')\n",
    "plt.ylabel('Ошибка')\n",
    "plt.show() # расскоментируйте, чтобы посмотреть \n",
    "        \n",
    "print(\"Точность нейронной сети \" + str(round(accuracy,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вывод: ПОвышение весов и понижение скорости обучения ведет к повышению получаемой точности"
   ]
  }
 ]
}